{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVMNiYseyWhDqsMNKI6YNa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This is a script for consolidating factoid lists based on the ontology mapping of all entities found in AP3 data.\n","\n","The package mainly uses the Pandas package in Python to read and manipulate EXCEL data as DataFrames. DataFrames are 2-dimensional data representations in rows and columns. They can be written to different file formats such as CSV, EXCEL, JSON or RDF.\n","\n","First of all, we need to connect this Colab notebook with your Google Drive and define the directory for input and output data.\n"],"metadata":{"id":"S3ydZRhYATDN"}},{"cell_type":"code","source":["## mount drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","directory=\"/content/drive/My Drive/Colab_DigiKAR/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39qqRJOgZmPC","executionInfo":{"status":"ok","timestamp":1674793545268,"user_tz":-60,"elapsed":35135,"user":{"displayName":"Monika Renate Barget","userId":"17857435992823422828"}},"outputId":"f6e77b93-0069-4da4-8dcd-f4aacf43e885"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["In the second step, we have to install additional Packages needed for working with CSV, EXCEL and DataFrames."],"metadata":{"id":"dCAdylkZL9f4"}},{"cell_type":"code","source":["## install packages that are not part of Python's standard distribution\n","\n","!pip install xlsxwriter\n","!pip install pandas\n","!pip install numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3d6OjjlTZ2ri","executionInfo":{"status":"ok","timestamp":1674793559264,"user_tz":-60,"elapsed":11084,"user":{"displayName":"Monika Renate Barget","userId":"17857435992823422828"}},"outputId":"b98015fb-7329-49a1-c476-b6adc1c36e0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting xlsxwriter\n","  Downloading XlsxWriter-3.0.7-py3-none-any.whl (152 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-3.0.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n"]}]},{"cell_type":"markdown","source":["Now we can import the packages to the script and load our data."],"metadata":{"id":"agRRVOwiOWXX"}},{"cell_type":"code","source":["## import relevant packages\n","\n","import xlsxwriter\n","import csv\n","import pandas as pd\n","from pandas import DataFrame\n","import numpy as np\n","import os\n","\n","# define files containing ontological mapping\n","\n","event_ontology='https://raw.githubusercontent.com/ieg-dhr/DigiKAR/main/OntologyFiles/event_ontology.csv' \n","#title_ontology='https://github.com/ieg-dhr/DigiKAR/blob/main/OntologyFiles/title_ontology.csv?raw=true' \n","#function_ontology='https://github.com/ieg-dhr/DigiKAR/blob/main/OntologyFiles/function_ontology.csv?raw=true'\n","place_ontology='https://raw.githubusercontent.com/ieg-dhr/DigiKAR/main/OntologyFiles/place_ontology.csv' \n","\n","# open ontology files\n","\n","# READ EVENTS\n","data_e = pd.read_csv(event_ontology, sep=\",\")\n","events_old=data_e['event_old'].values.tolist()\n","events_new=data_e['event_type'].values.tolist()\n","func_new=data_e['pers_function'].values.tolist()\n","    \n","# READ TITLES\n","#data_t = pd.read_csv(title_ontology, sep=\",\")\n","#title_old=data_t['title_old'].values.tolist()\n","#events_new=data_t['per_title'].values.tolist()\n","\n","# READ FUNCTIONS\n","#data_f = pd.read_csv(function_ontology, sep=\",\")\n","#function_old=data_f['function_old'].values.tolist()\n","#function_new=data_f['pers_function'].values.tolist()\n","\n","# READ PLACES\n","data_p = pd.read_csv(place_ontology, sep=\",\")\n","places_old=data_p['place_old'].values.tolist()\n","places_new=data_p['place_new'].values.tolist()\n","    \n"],"metadata":{"id":"spKIUGXb_TZV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The second step is to read all files in the input directory as one DataFrame and to manipulate the data."],"metadata":{"id":"TNFqD_PGXPmn"}},{"cell_type":"code","source":["# function to process data\n","\n","def extract_information(filenames):\n","        \n","# read all excel files in directory as one data frame\n","\n","    frame_list=[]\n","    for item in os.listdir(filenames):\n","        file = os.path.join(filenames, item)\n","        df = pd.read_excel(file, sheet_name='FactoidList', index_col=None, dtype=str) # axis=1, sort=False\n","        df = df.fillna(\"@\") # replace empty fields for string\n","        frame_list.append(df)\n","\n","    f = pd.concat(frame_list, axis=0, ignore_index=False, sort=False)\n","    print(f['event_name'])\n","\n","    # replace words in EVENT column & check if corresponding function needs to be updated\n","            \n","    for e_old in events_old:\n","        try:\n","            e_new=data_e.loc[data_e['event_old'] == e_old, 'event_type'].values[0]\n","            print(type(e_new))\n","            f['event_name'] = f['event_name'].replace(e_old, e_new)\n","\n","# check if event results in a specific function and add it if necessary\n","\n","            f_rel=data_e.loc[data_e['title_old'] == e_old, 'pers_function'].values[0]\n","            \n","            if f_rel==True:\n","                f['title_old'] = f['title_old'].replace(e_old, e_new)\n","            else:\n","                print(\"No function found.\")\n","                continue\n","            \n","        except KeyError:\n","            print(\"No mapping.\")\n","            continue\n","\n","\n","# write all results to new EXCEL file\n","\n","    workbook=directory+'FACTOIDS_mapped/Profs_mapped.xlsx'\n","    writer = pd.ExcelWriter(workbook, engine='xlsxwriter') # create a Pandas Excel writer using XlsxWriter as the engine.\n","    f.to_excel(writer, sheet_name='Mapped2') # Convert the dataframe to an XlsxWriter Excel object.\n","    writer.save() # Close the Pandas Excel writer and output the Excel file."],"metadata":{"id":"01A6V6eT0jDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''            \n","# find \"hidden\" places rows and add values to PLACE column\n","            \n","    for p in places_new:\n","        print(p)\n","        try:\n","            p_add=f[f[\"place_new\"].map(lambda place_new: p in place_new) & f[\"inst_name\"].map(lambda inst_name: p in inst_name)]\n","            print(p_add)\n","            \n","# Still raises ValueError: Columns must be same length as key\n","# Code will be fixed ASAP\n","\n","            f['place_name'] =(f['place_name'].map(str) + \"/\" + p_add)\n","            \n","        except KeyError:\n","            print(\"Key Error\")\n","            continue\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"id":"inH66sULAvnM","executionInfo":{"status":"ok","timestamp":1674793741861,"user_tz":-60,"elapsed":79,"user":{"displayName":"Monika Renate Barget","userId":"17857435992823422828"}},"outputId":"895a90db-a9fb-4a90-db57-d5c07d8fca8a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'            \\n# find \"hidden\" places rows and add values to PLACE column\\n            \\n    for p in places_new:\\n        print(p)\\n        try:\\n            p_add=f[f[\"place_new\"].map(lambda place_new: p in place_new) & f[\"inst_name\"].map(lambda inst_name: p in inst_name)]\\n            print(p_add)\\n            \\n# Still raises ValueError: Columns must be same length as key\\n# Code will be fixed ASAP\\n\\n            f[\\'place_name\\'] =(f[\\'place_name\\'].map(str) + \"/\" + p_add)\\n            \\n        except KeyError:\\n            print(\"Key Error\")\\n            continue\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# iterate through all XLSX files in directoy    \n","\n","def main():\n","    filenames = directory+\"FACTOIDS_to_map\"\n","    extract_information(filenames)\n","    print(\"Done.\") \n","\n","if __name__ == \"__main__\":\n","    main() \n","    \n","# ADDITIONAL OPTIONS:\n","\n","'''            \n","# replace words in TITLE column\n","            \n","    for t_old in title_old:\n","        print(t_old)\n","        try:\n","            t_new=data.loc[data['title_old'] == t_old, 'pers_title'].values[0]\n","            print(e_new)\n","            f['title_old'] = f['title_old'].replace(t_old, t_new)                \n","            \n","        except KeyError:\n","            print(\"Key Error\")\n","            continue\n","            \n","# replace words in FUNCTION column\n","            \n","    for f_old in function_old:\n","        print(f_old)\n","        try:\n","            f_new=data_f.loc[data_f['event_name'] == f_old, 'event_type'].values[0]\n","            print(f_new)\n","            f['event_name'] = f['event_name'].replace(f_old, f_new)\n","            \n","        except KeyError:\n","            print(\"Key Error\")\n","            continue\n","            \n","        print(f)\n","'''\n","\n","print(\"All data mapped!\")\n"],"metadata":{"id":"qG0aDIfMAhxw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674793823583,"user_tz":-60,"elapsed":2536,"user":{"displayName":"Monika Renate Barget","userId":"17857435992823422828"}},"outputId":"c8ae0902-4b58-4026-b2c9-93dd70818b33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0                          Lehrtätigkeit\n","1                   Berufliche Tätigkeit\n","2                   Berufliche Tätigkeit\n","3                   Akademische Laufbahn\n","4                                  birth\n","                      ...               \n","3632                      Lehrtätigkeit \n","3633               Erhalt einer Präbende\n","3634                Akademische Laufbahn\n","3635    Übernahme eines politischen Amts\n","3636    Übernahme eines politischen Amts\n","Name: event_name, Length: 3637, dtype: object\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","<class 'str'>\n","No mapping.\n","Done.\n","All data mapped!\n"]}]},{"cell_type":"markdown","source":["Check the output files and repeat process with refined ontology files if necessary.\n","\n","Script by Monika Barget, Maastricht/Mainz\n","\n","January 2023\n"],"metadata":{"id":"GBSEVpnKXS_u"}}]}