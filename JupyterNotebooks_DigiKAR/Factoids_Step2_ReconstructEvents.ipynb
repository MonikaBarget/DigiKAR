{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPsu7foz+95n3XueEsXVAqD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This is a script for consolidating factoid lists in AP3.\n","\n","The package mainly uses the Pandas package in Python to read and manipulate EXCEL data as DataFrames. DataFrames are 2-dimensional data representations in rows and columns. They can be written to different file formats such as CSV, EXCEL, JSON or RDF.\n","\n","First of all, we need to connect this Colab notebook with your Google Drive and define the directory for input and output data.\n"],"metadata":{"id":"S3ydZRhYATDN"}},{"cell_type":"code","source":["## mount drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","directory=\"/content/drive/My Drive/Colab_DigiKAR/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39qqRJOgZmPC","executionInfo":{"status":"ok","timestamp":1674823656194,"user_tz":-60,"elapsed":2219,"user":{"displayName":"Monika Renate Barget","userId":"17857435992823422828"}},"outputId":"bdfcd4d7-1118-4984-db29-37ff21a47e6a"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["In the second step, we have to install additional Packages needed for working with CSV, EXCEL and DataFrames."],"metadata":{"id":"dCAdylkZL9f4"}},{"cell_type":"code","source":["## install packages that are not part of Python's standard distribution\n","\n","!pip install xlsxwriter\n","!pip install pandas\n","!pip install numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3d6OjjlTZ2ri","executionInfo":{"status":"ok","timestamp":1674823673860,"user_tz":-60,"elapsed":10971,"user":{"displayName":"Monika Renate Barget","userId":"17857435992823422828"}},"outputId":"2f4f6ed2-778d-49ff-911d-5593e188ee99"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.8/dist-packages (3.0.7)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n"]}]},{"cell_type":"markdown","source":["Now we can import the packages to the script and load our data."],"metadata":{"id":"agRRVOwiOWXX"}},{"cell_type":"code","source":["# Script to sort event per person by event value and date\n","\n","# written for the DigiKAR geohumanities project in September 2021 by Monika Barget\n","\n","import xlsxwriter\n","import csv\n","import pandas as pd\n","from pandas import DataFrame\n","import numpy as np\n","import os\n","\n","# path to input files\n","\n","factoid_path=directory+'FACTOIDS_to_consolidate'\n","\n","# structure of input files\n","\n","# obligatory columns in valid factoid list\n","\n","column_names = [\"factoid_ID\",\n","                \"pers_ID\",\n","                \"alternative_names\",\n","                \"event_type\",\n","                \"event_after-date\",\n","                \"event_before-date\",\n","                \"event_start\",\n","                \"event_end\",\n","                \"event_date\",\n","                \"pers_title\",\n","                \"pers_function\",\n","                \"place_name\",\n","                \"inst_name\",\n","                \"rel_pers\",\n","                \"source_quotations\",\n","                \"additional_info\",\n","                \"comment\",\n","                \"info_dump\",\n","                \"source\",\n","                \"source_site\"]\n","                \n","frame_list=[]\n","for item in os.listdir(factoid_path):\n","    file = os.path.join(factoid_path, item)\n","    print(file)\n","    df = pd.read_excel(file, sheet_name='FactoidList', index_col=None, dtype=str) # axis=1, sort=False\n","    df = df.fillna(\"n/a\") # replace empty fields for string\n","    frame_list.append(df)\n","\n","f = pd.concat(frame_list, axis=0, ignore_index=False, sort=False)\n","\n","print(\"There are \", len(f), \"items in your DataFrame!\")\n","\n","# delete all duplicate rows with exact matches\n","\n","f_unique=f.drop_duplicates()\n","print(\"Your DataFrame has now \", len(f_unique), \"items with at least one unique cell.\" )\n","\n","# ranking of events if no time is given\n","\n","event_hierarchy_dict={\n","                  \"Geburt\":\"Taufe\",\n","                  \"Geburt\":\"Tod\",\n","                  \"Geburt\":\"Taufe\",\n","                  \"Geburt\":\"Taufe\",\n","                  \"Geburt\":\"Taufe\",\n","                  \"Geburt\":\"Taufe\", \n","                  \"Primäre Bildungsstation\" # Beziehung zu \"Privatunterricht\"?\n","                  # Welche Beziehung haben \"Rezeption\" und \"Zulassung\" zueinander oder zu anderen Ergeignissen?\n","                  \"Immatrikulation\":\"Studium\",\n","                  \"Prüfungsverfahren\":\"Graduation\",\n","                  \"Studium\":\"Promotion\",\n","                  \"Aufnahme\":\"Funktionsausübung\",\n","                  \"Aufschwörung\":\"Funktionssausübung\",\n","                  \"erfolglose Bewerbung\":\"Funktionssausübung\",\n","                  \"Aufenthalt\" # Bezug zu \"Reise\"?\n","                  \"Introduktion\":\"Mitgliedschaft\" # Nur in dieser Kombination möglich?\n","                  \"Präsentation\" # Bezug zu anderen Ereignissen?\n","                  \"Vokation\":\"Funktionsausübung\",\n","                  \"Ernennung\":\"Funktionsausübung\",\n","                  \"Amtseinführung\":\"Funktionsausübung\",\n","                  \"Vereidigung\":\"Funktionsausübung\",\n","                  \"Amtsantritt\":\"Funktionsausübung\",\n","                  \"Beförderung\":\"Funktionsausübung\",\n","                  \"Funktionsausübung\":\"Entlassung\",\n","                  \"Funktionsausübung\":\"Suspendierung\",\n","                  \"Funktionsausübung\":\"Absetzung\",\n","                  \"Funktionsausübung\":\"Resignation\",\n","                  \"Funktionsausübung\":\"Rücktritt\",\n","                  \"Funktionsausübung\":\"Pensionierung\",\n","                  \"Funktionsausübung\":\"Pension\",\n","                  \"Funktionsausübung\":\"Tod\"}\n","\n","event_value_dict={\"Sonstiges\":0, \n","                  \"Geburt\":1, \n","                  \"Taufe\":2, \n","                  \"Primäre Bildungsstation\":3, \n","                  \"Privatunterricht\":3,\n","                  \"Rezeption\":10, # nicht sicher ob bezogen auf Studium?\n","                  \"Zulassung\":10, # vor dem Studium, oder z.B. auch zur Prüfung?\n","                  \"Immatrikulation\":10,\n","                  \"Studium\":10,\n","                  \"Prüfungsverfahren\":10,\n","                  \"Graduation\":10,\n","                  \"Praktikum\":10,\n","                  \"Promotion\":10,\n","                  \"Wohnsitznahme\": 10,\n","                  \"Reise\":20, # Events mit Code \"20\" können in der Lebensmitte mehrfach auftreten\n","                  \"Nobilitierung\":20,\n","                  \"Aufnahme\":20,\n","                  \"Aufschwörung\":20,\n","                  \"Eheschließung\":20,\n","                  \"Funktionsausübung\":20,\n","                  \"erfolglose Bewerbung\":20,\n","                  \"Rejektion\":20,\n","                  \"Aufenthalt\":20,\n","                  \"mittelbare Nobilitierung\":20,\n","                  \"Privilegierung\":20,\n","                  \"Wappenbesserung\":20,\n","                  \"Introduktion\":30, # bezogen worauf?\n","                  \"Mitgliedschaft\":30,\n","                  \"Gesandtschaft\":30, # vermutlich nicht für ganz junge Personen?\n","                  \"Präsentation\":30, # nicht sicher was das ist...\n","                  \"Vokation\":39, # Berufung an Uni?\n","                  \"Ernennung\":40,\n","                  \"Amtseinführung\":41,\n","                  \"Vereidigung\":41,\n","                  \"Amtsantritt\":42,\n","                  \"Beförderung\":44, # wie oft werden Personen durchschnittlich befördert?\n","                  \"Ehrung\":45, # vermutlich bei Personen ab Lebensmitte?\n","                  \"Entlassung\":50,\n","                  \"Suspendierung\":50,\n","                  \"Absetzung\":50,\n","                  \"Resignation\":50,\n","                  \"Rücktritt\":50,\n","                  \"Pensionierung\":90,\n","                  \"Pension\":91,\n","                  \"Tod\":100}\n","\n","# read person list\n","\n","pers_name_f=(f[['pers_name']]) \n","search_df=pers_name_f.drop_duplicates() # remove duplicates\n","search_list=search_df['pers_name'].tolist()\n","\n","# count no. of entries in flattened person list\n","\n","no_person=len(search_list)\n","print(\"There are\", no_person, \"unique person names in this data set.\")\n","\n","# iterate through unique persons to get their events\n","\n","frame_list=[]\n","for name in search_list:\n","    res_df=(f.loc[f['pers_name'] == name])\n","\n","# check tricky events    \n","    bio_events=res_df['event_type'].values.tolist()\n","    print(bio_events)\n","    bio_check=[]\n","    prime_suspects=[]\n","    for b in bio_events:\n","        if str(b) not in bio_check:\n","            bio_check.append(str(b))\n","        else:\n","          prime_suspects.append(str(b))\n","\n","    print(name, prime_suspects)\n","\n","# aggregate similar events\n","\n","    df_new = res_df.groupby([\"event_type\", \"place_name\"]).agg(\n","                                  {\"event_after-date\":'min',\n","                                  \"event_before-date\":'max',\n","                                  \"event_start\":'min',\n","                                  \"event_end\":'min',\n","                                  \"factoid_ID\":list,\n","                                  \"pers_ID\":list,\n","                                  \"pers_name\":list,\n","                                  \"alternative_names\":list,\n","                                  \"pers_title\":list,\n","                                  \"pers_function\":list,\n","                                  \"inst_name\":list,\n","                                  \"rel_pers\":list,\n","                                  \"source_quotations\":list,\n","                                  \"additional_info\":list,\n","                                  \"comment\":list,\n","                                  \"info_dump\":list,\n","                                  \"source\":list,\n","                                  \"source_site\":list} \n","                                  )\n","    frame_list.append(df_new)\n","\n","f_result = pd.concat(frame_list, axis=0, ignore_index=False, sort=False)\n","\n","# add event values from dict to data frame\n","\n","f_result['event_value'] = f_result['event_type'].map(event_value_dict)\n","f_result.sort_values(by =['event_after-date','event_start','event_before-date', 'event_end', 'event_value'])\n","\n","print(\"Aggregation complete!\")\n","display(f_result) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"zYkO-hJ7rxxb","executionInfo":{"status":"error","timestamp":1674898907636,"user_tz":-60,"elapsed":399,"user":{"displayName":"Monika Renate Barget","userId":"17857435992823422828"}},"outputId":"3ba4d71c-4b03-47c2-cd04-dfae65ab5920"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a94bff73209f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# written for the DigiKAR geohumanities project in September 2021 by Monika Barget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxlsxwriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xlsxwriter'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["\n","\n","   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":515},"id":"Q9LhQmFD-Y9h","executionInfo":{"status":"error","timestamp":1674824078096,"user_tz":-60,"elapsed":323,"user":{"displayName":"Monika Renate Barget","userId":"17857435992823422828"}},"outputId":"4174287e-d917-49b3-837e-9c08585e4848"},"execution_count":56,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'event_type'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-895f0c09634d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# double-check tricky events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbio_events\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'event_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbio_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprime_suspects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbio_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'event_type'"]}]},{"cell_type":"markdown","source":["The final step is to write the results to a single output file."],"metadata":{"id":"8wRkCp062_jJ"}},{"cell_type":"code","source":["# write all results to new EXCEL file\n","\n","workbook=directory+'FACTOIDS_consolidated/Factoid_consolidated.xlsx'\n","print(workbook)\n","writer = pd.ExcelWriter(workbook, engine='xlsxwriter') # create a Pandas Excel writer using XlsxWriter as the engine.\n","f_result.to_excel(writer, sheet_name='FactCons') # Convert the dataframe to an XlsxWriter Excel object.\n","writer.save() # Close the Pandas Excel writer and output the Excel file.\n","print(\"Done.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qmxPBH9Q3FY_","executionInfo":{"status":"ok","timestamp":1674823892175,"user_tz":-60,"elapsed":1131,"user":{"displayName":"Monika Renate Barget","userId":"17857435992823422828"}},"outputId":"1e78894d-fce9-40fd-9a60-ecac3305fbb7"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab_DigiKAR/FACTOIDS_consolidated/Factoid_consolidated.xlsx\n","Done.\n"]}]},{"cell_type":"markdown","source":["Check the output files and repeat process if necessary.\n","\n","Script by Monika Barget, Maastricht/Mainz\n","\n","January 2023\n"],"metadata":{"id":"GBSEVpnKXS_u"}}]}
